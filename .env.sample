# ============================================================================
# Clockify RAG Stack - Advanced Multi-Corpus Configuration
# ============================================================================

# LOCAL LLM ENDPOINT (OpenAI-compatible)
MODEL_BASE_URL=http://127.0.0.1:8000/v1
MODEL_API_KEY=sk-local-or-empty
MODEL_NAME=oss20b
MODEL_MAX_TOKENS=1000
MODEL_TEMPERATURE=0.7

# EMBEDDING MODEL
EMBEDDING_MODEL=intfloat/multilingual-e5-base
EMBEDDING_BATCH_SIZE=32
EMBEDDING_POOL_SIZE=4

# ============================================================================
# MULTI-CORPUS CONFIGURATION
# ============================================================================

# Crawl base URLs (comma-separated)
CRAWL_BASES=https://clockify.me/help/,https://docs.langchain.com

# Domain whitelist (comma-separated, matches crawl sources)
DOMAINS_WHITELIST=clockify.me,docs.langchain.com

# Namespace mapping: if not set, inferred from domain
# Format: domain=namespace (one per line or comma-separated)
# NAMESPACE_MAP=clockify.me=clockify,docs.langchain.com=langchain

# ============================================================================
# CRAWL BEHAVIOR
# ============================================================================

CRAWL_CONCURRENCY=4
CRAWL_DELAY_SEC=1
CRAWL_ALLOW_OVERRIDE=false
CRAWL_MAX_PAGES=500
CRAWL_TIMEOUT=30

# ============================================================================
# CHUNKING & PARENT-CHILD INDEXING
# ============================================================================

# Parent nodes: section-level, ~3–5k tokens
PARENT_CHUNK_TOKENS=3500
PARENT_CHUNK_OVERLAP_TOKENS=300

# Child nodes: ~800–1200 tokens with ~15% overlap
CHILD_CHUNK_TOKENS=1000
CHILD_CHUNK_OVERLAP_TOKENS=150
CHILD_CHUNK_MIN_TOKENS=100

# Enable parent-child indexing (retrieves children, expands to parents for context)
PARENT_CHILD_INDEXING=true

# ============================================================================
# HYBRID SEARCH (Vector + BM25)
# ============================================================================

# Enable BM25 full-text search in addition to vector search
HYBRID_SEARCH=true

# BM25 tuning (Okapi BM25 parameters)
BM25_K1=1.5
BM25_B=0.75

# Hybrid fusion: how to combine vector and BM25 scores
# Options: reciprocal_rank_fusion (default), linear_blend
HYBRID_FUSION=reciprocal_rank_fusion
HYBRID_FUSION_WEIGHT=0.5

# ============================================================================
# QUERY REWRITING (Advanced retrieval)
# ============================================================================

# Enable query rewrites to generate diverse search queries
QUERY_REWRITES=true

# Rewrite types (comma-separated): multiquery,hyde
# - multiquery: generate 3–5 diverse rewrites of the original query
# - hyde: Hypothetical Document Embeddings (generate ideal answer, then search for similar)
REWRITE_METHODS=multiquery,hyde

# Number of rewrites to generate
REWRITE_COUNT=3

# ============================================================================
# RERANKING (Cross-encoder post-processing)
# ============================================================================

# Enable cross-encoder reranking to improve result quality
USE_RERANKER=true

# Reranker model (BAAI models are lightweight and effective)
RERANKER_MODEL=BAAI/bge-reranker-base

# Reranker batch size
RERANKER_BATCH_SIZE=32

# Keep top-K results after reranking
RERANKER_TOP_K=5

# ============================================================================
# RETRIEVAL API
# ============================================================================

API_HOST=0.0.0.0
API_PORT=7000
API_WORKERS=4

# Default retrieval parameters
RETRIEVAL_TOP_K=5
RETRIEVAL_MAX_K=20

# Max context tokens to include in LLM prompt
RETRIEVAL_MAX_CONTEXT_TOKENS=4000

# ============================================================================
# CITATIONS & FORMATTING
# ============================================================================

# Enable inline bracketed citations [1], [2] in responses
USE_CITATIONS=true

# Include sources section at end of response
INCLUDE_SOURCES=true

# Format for sources: "markdown" or "json"
SOURCES_FORMAT=markdown

# ============================================================================
# LOGGING & DEBUGGING
# ============================================================================

LOG_LEVEL=INFO
DEBUG=false

# Save retrieval traces for debugging
SAVE_TRACES=false
TRACES_DIR=./traces

# ============================================================================
